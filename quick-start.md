---
title: Quick Start  
description: Getting started with LangStream
image: /images/chatbot-us-presidents.gif
---
Getting started on Mac with LangStream is easy. You only need to have [Homebrew](https://docs.brew.sh/Installation) and [Docker](https://docs.docker.com/desktop/install/mac-install/) installed.

### 1. Install LangStream using Homebrew

```bash
brew tap LangStream/langstream
brew install langstream
```

### 2. Set OpenAI key in an environment variable

```bash
export OPENAI_API_KEY=your-key-here
```

### 3. Start LangStream application using Docker

```bash
langstream docker run test \
  -app https://github.com/LangStream/langstream/blob/main/examples/applications/openai-completions \
  -s https://github.com/LangStream/langstream/blob/main/examples/secrets/secrets.yaml
```

This will download the `openai-completions` example from the LangStream repository and run it using the default secrets file, which expects the secrets in environment variables. The application provides a complete backend for a chatbot that uses OpenAI's GPT-3.5-turbo to generate responses. It includes a WebSocket gateway for easy access to the streaming AI agents from application environments including web browsers.

### 4. Connect to the WebSocket gateway using the built-in chat client

In a different terminal window:

```bash
langstream gateway chat test -cg consume-output -pg produce-input -p sessionId=$(uuidgen)
```
The output will be streamed in real-time as it is generated by the LLM. The gateway supports multiple concurrent users by specifying a unique `sessionId` for each.

### 5. Chat with the bot
![Chatbot asking about US presidents](/images/chatbot-us-presidents.gif)



### Next steps

* [Build a sample app in the LangStream documentation](https://docs.langstream.ai/building-applications/build-a-sample-app/).

* [Install LangStream in Kubernetes](https://docs.langstream.ai/installation/kubernetes)
